{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a6ce07",
   "metadata": {},
   "source": [
    "# Parallelizing Neural Network Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979feb0",
   "metadata": {},
   "source": [
    "## Creating tensors in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exempt-sperm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.759987Z",
     "start_time": "2021-10-04T01:36:50.265461Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adapted-muscle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.775963Z",
     "start_time": "2021-10-04T01:36:54.761959Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "visible-water",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.791966Z",
     "start_time": "2021-10-04T01:36:54.778965Z"
    }
   },
   "outputs": [],
   "source": [
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "general-dublin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.807002Z",
     "start_time": "2021-10-04T01:36:54.794966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# print tensors with their properties \n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01296169",
   "metadata": {},
   "source": [
    "This resulted in tensors `t_a` and `t_b`, with their properties, `shape=(3,)` and `dtype=int32`, adopted from their source.  Similar to NumPy arrays, we can further see these properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empty-designer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.837965Z",
     "start_time": "2021-10-04T01:36:54.808965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones = tf.ones((2, 3))\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3ff98c",
   "metadata": {},
   "source": [
    "To get access to the values that a tensor refers to, we can simply call the `.numpy()` method on a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "younger-belief",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.853963Z",
     "start_time": "2021-10-04T01:36:54.840965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d1348",
   "metadata": {},
   "source": [
    "Finally, creating a tensor of constant values can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alleged-factor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.868962Z",
     "start_time": "2021-10-04T01:36:54.857963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.2   5.    3.142], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# create tensor with constant values\n",
    "const_tensor = tf.constant([1.2, 5, np.pi],\n",
    "                          dtype=tf.float32)\n",
    "print(const_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d0de8",
   "metadata": {},
   "source": [
    "## Manipulating the date type and shape of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c1ec89",
   "metadata": {},
   "source": [
    "The `tf.cast()` function can be used to change the date type of a tensor to a desired type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "institutional-armstrong",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.884009Z",
     "start_time": "2021-10-04T01:36:54.870963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "# t_cast function can be used to change dtype\n",
    "t_a_new = tf.cast(t_a, tf.int64)\n",
    "print(t_a_new.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "removable-overall",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.899966Z",
     "start_time": "2021-10-04T01:36:54.889965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)  -->  (5, 3)\n"
     ]
    }
   ],
   "source": [
    "# transposing a tensor\n",
    "t = tf.random.uniform(shape=(3, 5))\n",
    "t_tr = tf.transpose(t)\n",
    "print(t.shape, ' --> ', t_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-transfer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.915965Z",
     "start_time": "2021-10-04T01:36:54.901958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n"
     ]
    }
   ],
   "source": [
    "# reshaping a tensor (for example, from 1D vector to 2D array)\n",
    "t = tf.zeros((30,))\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "print(t_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "simple-valuable",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.931965Z",
     "start_time": "2021-10-04T01:36:54.917959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 1, 4, 1)  -->  (1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "# removing the unnecessary dimensions (dimensions that have size 1, which are not needed)\n",
    "t = tf.zeros((1, 2, 1, 4, 1))\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4))\n",
    "print(t.shape, ' --> ', t_sqz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-kazakhstan",
   "metadata": {},
   "source": [
    "## Applying Mathematical Operations to Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01996cf8",
   "metadata": {},
   "source": [
    "First, let's instantiate two random tensors, one with uniform distribution in the range [1, 1) and the othe rwith a standard normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sharing-alaska",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.947966Z",
     "start_time": "2021-10-04T01:36:54.933958Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sustained-monthly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.963965Z",
     "start_time": "2021-10-04T01:36:54.949964Z"
    }
   },
   "outputs": [],
   "source": [
    "t1 = tf.random.uniform(shape=(5, 2),\n",
    "                      minval=-1.0, maxval=1.0)\n",
    "\n",
    "t2 = tf.random.normal(shape=(5, 2), \n",
    "                      mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a5894",
   "metadata": {},
   "source": [
    "Notice that `t1` and `t2` have the same shape.  Now to compute the element-wise product of `t1` and `t2`, we can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "durable-supplement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.979960Z",
     "start_time": "2021-10-04T01:36:54.965963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27  -0.874]\n",
      " [-0.017 -0.175]\n",
      " [-0.296 -0.139]\n",
      " [-0.727  0.135]\n",
      " [-0.401  0.004]]\n"
     ]
    }
   ],
   "source": [
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca17b93",
   "metadata": {},
   "source": [
    "To compute the mean, sum, and standard deviation along a certain axis (or axes), we can use `tf.math.reduce_mean()`, `tf.math.reduce_sum()`, and `tf.math.reduce_std()`.  For example, the mean of each column in `t1` can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "established-seafood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:54.995961Z",
     "start_time": "2021-10-04T01:36:54.983961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.09  0.207], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t4 = tf.math.reduce_mean(t1, axis=0)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc89828",
   "metadata": {},
   "source": [
    "The matrix-matrix product between `t1` and `t2` (that is, *`t1 x t2`*, where the superscript `T` is for transpose) can be computed by using the `tf.linalg.matmul()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "presidential-poetry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.041962Z",
     "start_time": "2021-10-04T01:36:54.998960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.144  1.115 -0.87  -0.321  0.856]\n",
      " [ 0.248 -0.191  0.25  -0.064 -0.331]\n",
      " [-0.478  0.407 -0.436  0.022  0.527]\n",
      " [ 0.525 -0.234  0.741 -0.593 -1.194]\n",
      " [-0.099  0.26   0.125 -0.462 -0.396]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10337ca",
   "metadata": {},
   "source": [
    "On the other hand, computing *`t1 x t2`* is performed by transporting `t1`, resulting in an array of size 2x2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acting-newark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.057967Z",
     "start_time": "2021-10-04T01:36:55.044966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.711  0.302]\n",
      " [ 0.371 -1.049]]\n"
     ]
    }
   ],
   "source": [
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "print(t6.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847776ae",
   "metadata": {},
   "source": [
    "Finally the `tf.norm()` function is useful for computing the \\\\( L^p \\\\) norm of a tensor.  For example, we can calculate the \\\\( L^2 \\\\) norm of `t1` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surprised-granny",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.073973Z",
     "start_time": "2021-10-04T01:36:55.059963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.046 0.293 0.504 0.96  0.383]\n"
     ]
    }
   ],
   "source": [
    "# useful for computing Lp norm of a tensor\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "print(norm_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e959047",
   "metadata": {},
   "source": [
    "To verify that this code snippet computes the \\\\( L^2 \\\\) norm of `t1` correctly, you can compare the results with the following NumPy function: `np.sqrt(np.sum(np.square(t1), axis=1))`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-potential",
   "metadata": {},
   "source": [
    "## Split, stack, and concatenate tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7d00f",
   "metadata": {},
   "source": [
    "Providing the number of splits (must be divisible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "physical-dynamics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:37:45.596602Z",
     "start_time": "2021-10-04T01:37:45.586594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292 0.643]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6, ))\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "center-algeria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:37:51.493835Z",
     "start_time": "2021-10-04T01:37:51.482791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.165, 0.901], dtype=float32),\n",
       " array([0.631, 0.435], dtype=float32),\n",
       " array([0.292, 0.643], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_splits = tf.split(t, num_or_size_splits=3)\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e402882",
   "metadata": {},
   "source": [
    "In this example, a tensor of size 6 was divided into a list of three tensors each with size 2.\n",
    "\n",
    "Providing the sizes of different splits:\n",
    "\n",
    "Alternatively, instead of defining the number of splits, we can also specify the sizes of the output tensors directly.  Here we are spliiting a tensor of size 5 into tensors of sizes 3 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "boolean-canal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.121960Z",
     "start_time": "2021-10-04T01:36:55.108966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5, ))\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d388102",
   "metadata": {},
   "source": [
    "Sometimes, we are working with multiple tensors and need to concatenate or stack them to create a single tensor.  In this case, TensorFlow functions such as `tf.stack()` and `tf.concat()` come in handy.  For example, let's create a 1D tensor, `A`, containing 1s with size 3 and a 1D tensor, `B`, containing 0s with size 0s with size 2 and concatenate them into a 1D tensor, `C`, of size 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "closed-representative",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.137960Z",
     "start_time": "2021-10-04T01:36:55.128967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.165, 0.901, 0.631], dtype=float32),\n",
       " array([0.435, 0.292], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eleven-friendly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.153957Z",
     "start_time": "2021-10-04T01:36:55.142961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3, ))\n",
    "B = tf.zeros((2, ))\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36054296",
   "metadata": {},
   "source": [
    "If we create a 1D tensors `A` and `B`, both with size 3, then we can stack them together to form a 2D tensor, S:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "closing-limit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.168960Z",
     "start_time": "2021-10-04T01:36:55.157962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3, ))\n",
    "B = tf.zeros((3, ))\n",
    "S = tf.stack([A, B], axis=1)\n",
    "print(S.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-mercury",
   "metadata": {},
   "source": [
    "## Creating a TensorFlow Dataset From Exisiting Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520b140",
   "metadata": {},
   "source": [
    "Consider the following code, which creates a dataset from a list of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "lovely-startup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.184957Z",
     "start_time": "2021-10-04T01:36:55.170961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe3980",
   "metadata": {},
   "source": [
    "We can easily iterate through a dataset entry by entry as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eight-standing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.215995Z",
     "start_time": "2021-10-04T01:36:55.186958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for item in ds:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606adaee",
   "metadata": {},
   "source": [
    "If we want to create batches from this dataset, with a desired batch size of 3, we can do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "suited-cloud",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.247993Z",
     "start_time": "2021-10-04T01:36:55.218957Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: [1.2 3.4 7.5]\n",
      "batch 2: [4.1 5.  1. ]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(3)\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print('batch {}:'.format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-vertical",
   "metadata": {},
   "source": [
    "## Combining Two Tensors into a Joint Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9889662c",
   "metadata": {},
   "source": [
    "Assume that we have two tensors, `t_x` and `t_y`.  Tensor `t_x` holds our feature values, each of 3, and `t_y` stores the class labels.  For this example, we first create these two tensors as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "collected-institute",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.263963Z",
     "start_time": "2021-10-04T01:36:55.249967Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)\n",
    "t_y = tf.range(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f7c62",
   "metadata": {},
   "source": [
    "Now, we want to create a joint dataset from these two tensors.  Note that there is a required one-to-one correspondence between the elements of these two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e32817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "domestic-ontario",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T02:29:24.519100Z",
     "start_time": "2021-10-04T02:29:24.447563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.165 0.901 0.631]   y: 0\n",
      "x: [0.435 0.292 0.643]   y: 1\n",
      "x: [0.976 0.435 0.66 ]   y: 2\n",
      "x: [0.605 0.637 0.614]   y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\n",
    "\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "for example in ds_joint:\n",
    "    print('x:', example[0].numpy(),\n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf45fcb",
   "metadata": {},
   "source": [
    "Here, we first created two separate datasets, namely `ds_x` and `ds_y`.  We then used the `zip` function to form a joint dataset.  Alternatively, we can create the joint dataset using `tf.data.Datset.from_tensor_slices()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aea7ea64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T02:36:18.718040Z",
     "start_time": "2021-10-04T02:36:18.693930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.165 0.901 0.631]   y: 0\n",
      "x: [0.435 0.292 0.643]   y: 1\n",
      "x: [0.976 0.435 0.66 ]   y: 2\n",
      "x: [0.605 0.637 0.614]   y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y))\n",
    "for example in ds_joint:\n",
    "    print('x:', example[0].numpy(),\n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341338e3",
   "metadata": {},
   "source": [
    "Next, we will see how to apply transformation to each individual element of a dataset.  For this, we will use the previous `ds_joint` dataset and apply feature-scaling to scale the values to the range [-1, 1), as currently the values ot `t_x` are in the range [0, 1) based on random uniform distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "regional-ideal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.422959Z",
     "start_time": "2021-10-04T01:36:55.314970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [-0.67   0.803  0.262]   y: 0\n",
      "x: [-0.131 -0.416  0.285]   y: 1\n",
      "x: [ 0.952 -0.13   0.32 ]   y: 2\n",
      "x: [0.21  0.273 0.229]   y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1.0, y))\n",
    "for example in ds_trans:\n",
    "    print('x:', example[0].numpy(),\n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3ffc5",
   "metadata": {},
   "source": [
    "Applying this sort of transformation can be used for a user-defined function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-possible",
   "metadata": {},
   "source": [
    "## Shuffle, batch, and repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9766a",
   "metadata": {},
   "source": [
    "First, let's create a shuffled version from the `ds_joint` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sized-detection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.453968Z",
     "start_time": "2021-10-04T01:36:55.425995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.976 0.435 0.66 ]   y: 2\n",
      "x: [0.435 0.292 0.643]   y: 1\n",
      "x: [0.165 0.901 0.631]   y: 0\n",
      "x: [0.605 0.637 0.614]   y: 3\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size=len(t_x))\n",
    "for example in ds:\n",
    "    print('x:', example[0].numpy(),\n",
    "          '  y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd92e56",
   "metadata": {},
   "source": [
    "You'll recall that dividing a dataset into batches for model training by calling the `.batch()` method.  No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "brazilian-reform",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.485973Z",
     "start_time": "2021-10-04T01:36:55.456995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-x:\n",
      " [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(batch_size=3,\n",
    "                   drop_remainder=False)\n",
    "batch_x, batch_y = next(iter(ds))\n",
    "print('Batch-x:\\n', batch_x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "champion-sender",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.501993Z",
     "start_time": "2021-10-04T01:36:55.490967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-y:  [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print('Batch-y: ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "controlling-modeling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.533964Z",
     "start_time": "2021-10-04T01:36:55.503975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (1, 3) [3]\n",
      "2 (3, 3) [0 1 2]\n",
      "3 (1, 3) [3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(3).repeat(count=2)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sixth-installation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.565965Z",
     "start_time": "2021-10-04T01:36:55.536975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (3, 3) [3 0 1]\n",
      "2 (2, 3) [2 3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "combined-melissa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.611960Z",
     "start_time": "2021-10-04T01:36:55.568961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [2 1]\n",
      "1 (2, 3) [0 3]\n",
      "2 (2, 3) [0 3]\n",
      "3 (2, 3) [1 2]\n",
      "4 (2, 3) [3 0]\n",
      "5 (2, 3) [1 2]\n"
     ]
    }
   ],
   "source": [
    "## Order 1: shuffle -> batch -> repeat\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "limiting-currency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.642972Z",
     "start_time": "2021-10-04T01:36:55.614971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [0 1]\n",
      "1 (2, 3) [2 3]\n",
      "2 (2, 3) [0 1]\n",
      "3 (2, 3) [2 3]\n",
      "4 (2, 3) [2 3]\n",
      "5 (2, 3) [0 1]\n"
     ]
    }
   ],
   "source": [
    "## Order 2: batch -> shuffle -> repeat\n",
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-cartoon",
   "metadata": {},
   "source": [
    "## Create a dataset from files on your local storage disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "orange-recruitment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.657963Z",
     "start_time": "2021-10-04T01:36:55.646998Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "substantial-evidence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:55.673961Z",
     "start_time": "2021-10-04T01:36:55.663961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "imgdir_path = pathlib.Path('cat_dog_images')\n",
    "file_list = sorted([str(path) for path in\n",
    "                   imgdir_path.glob('*.jpg')])\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "special-dealer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:56.095958Z",
     "start_time": "2021-10-04T01:36:55.677960Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "individual-driving",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T01:36:56.111964Z",
     "start_time": "2021-10-04T01:36:56.098968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i, file in enumerate(file_list):\n",
    "    img_raw = tf.io.read_file(file)\n",
    "    img = tf.image.decode_image(img_raw)\n",
    "    print('Image shape: ', img.shape)\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(os.path.basename(file), size=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fdb9160099e666fbe1246fdc3611df6e34403c4a50d97f5ca90d3cacc6ef812"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
